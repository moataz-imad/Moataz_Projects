{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook:\n",
    "- Downloads the latest version of the glue notebooks from s3 bucket\n",
    "- Changes `%connections target_env_prod, stuff` to `%connections {target_env}, stuff`\n",
    "- Uploads the modified version back to s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of etls that we care about (taken from the step function)\n",
    "step_etls=[\n",
    "    # 'benefits.benefits_and_enrollment',\n",
    "    'benefits.company',\n",
    "    'benefits.company_address',\n",
    "    'benefits.company_onboarding_status',\n",
    "    'benefits.hra_program_class',\n",
    "    'benefits.reimbursement_rate',\n",
    "    'benefits.rmb_class_zip_county',\n",
    "    \n",
    "    'billing.company',\n",
    "    \n",
    "    'election-1-etp',\n",
    "    'election-2-rp and hbe',\n",
    "    \n",
    "    'funding',\n",
    "    \n",
    "    'people.address',\n",
    "    'people.company_admin',\n",
    "    'people.employment',\n",
    "    'people.person',\n",
    "    \n",
    "    'ledger.recurring_premiums',\n",
    "    'ledger.ledger',\n",
    "    'ledger.account',\n",
    "    'ledger.journal_entry - accrue allowance'\n",
    "    \n",
    "]\n",
    "target_env='target_env_migrate' # target_env_migrate, target_env_staging, target_env_prod, target_env_test\n",
    "\n",
    "source_folder = '0_inputs'\n",
    "results_folder = '1_results'\n",
    "\n",
    "bucket_name = 's3_bucket'\n",
    "prefix = 'notebooks/'  # The prefix or \"folder\" path in the S3 bucket\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Download the selected the notebooks from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/18 Downloading notebooks/benefits.company.ipynb to 0_inputs\\benefits.company.ipynb...\n",
      "2/18 Downloading notebooks/benefits.company_address.ipynb to 0_inputs\\benefits.company_address.ipynb...\n",
      "3/18 Downloading notebooks/benefits.company_onboarding_status.ipynb to 0_inputs\\benefits.company_onboarding_status.ipynb...\n",
      "4/18 Downloading notebooks/benefits.hra_program_class.ipynb to 0_inputs\\benefits.hra_program_class.ipynb...\n",
      "5/18 Downloading notebooks/benefits.reimbursement_rate.ipynb to 0_inputs\\benefits.reimbursement_rate.ipynb...\n",
      "6/18 Downloading notebooks/benefits.rmb_class_zip_county.ipynb to 0_inputs\\benefits.rmb_class_zip_county.ipynb...\n",
      "7/18 Downloading notebooks/billing.company.ipynb to 0_inputs\\billing.company.ipynb...\n",
      "8/18 Downloading notebooks/election-1-etp.ipynb to 0_inputs\\election-1-etp.ipynb...\n",
      "9/18 Downloading notebooks/election-2-rp and hbe.ipynb to 0_inputs\\election-2-rp and hbe.ipynb...\n",
      "10/18 Downloading notebooks/funding.ipynb to 0_inputs\\funding.ipynb...\n",
      "11/18 Downloading notebooks/ledger.account.ipynb to 0_inputs\\ledger.account.ipynb...\n",
      "12/18 Downloading notebooks/ledger.journal_entry - accrue allowance.ipynb to 0_inputs\\ledger.journal_entry - accrue allowance.ipynb...\n",
      "13/18 Downloading notebooks/ledger.ledger.ipynb to 0_inputs\\ledger.ledger.ipynb...\n",
      "14/18 Downloading notebooks/ledger.recurring_premiums.ipynb to 0_inputs\\ledger.recurring_premiums.ipynb...\n",
      "15/18 Downloading notebooks/people.address.ipynb to 0_inputs\\people.address.ipynb...\n",
      "16/18 Downloading notebooks/people.company_admin.ipynb to 0_inputs\\people.company_admin.ipynb...\n",
      "17/18 Downloading notebooks/people.employment.ipynb to 0_inputs\\people.employment.ipynb...\n",
      "18/18 Downloading notebooks/people.person.ipynb to 0_inputs\\people.person.ipynb...\n",
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the local directory where you want to save the files\n",
    "local_dir = source_folder\n",
    "if not os.path.exists(local_dir):\n",
    "    os.makedirs(local_dir)\n",
    "\n",
    "# List objects in the S3 bucket with the specified prefix\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "counter = 0\n",
    "total = len(step_etls)\n",
    "# Check if there are contents in the response\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        key = obj['Key']\n",
    "        # Skip if it's just the folder name\n",
    "        if key.endswith('/'):\n",
    "            continue\n",
    "        \n",
    "        # Only download if the file has a .ipynb extension\n",
    "        if key.endswith('.ipynb'):\n",
    "            k='.'.join(key.split('/')[-1].split('.')[:-1]) # etl name without the path nor the extension\n",
    "            # print(k)\n",
    "            if k in step_etls:\n",
    "                counter += 1\n",
    "                # Define the local file path\n",
    "                local_file_path = os.path.join(local_dir, key.split('/')[-1])\n",
    "                \n",
    "                # Download the file\n",
    "                print(f'{counter}/{total} Downloading {key} to {local_file_path}...')\n",
    "                s3.download_file(bucket_name, key, local_file_path)\n",
    "\n",
    "print(\"Download complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Modify selected notebooks (same notebooks from the step function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/19 benefits.company -> %connections target_env_migrate, bigquery\n",
      "2/19 benefits.company_address -> %connections target_env_migrate\n",
      "3/19 benefits.company_onboarding_status -> %connections target_env_migrate\n",
      "4/19 benefits.hra_program_class -> %connections target_env_migrate\n",
      "5/19 benefits.reimbursement_rate -> %connections target_env_migrate\n",
      "6/19 benefits.rmb_class_zip_county -> %connections target_env_migrate\n",
      "7/19 billing.company -> %connections target_env_migrate\n",
      "8/19 election-1-etp -> %connections target_env_migrate\n",
      "9/19 election-2-ss and hbe -> %connections target_env_migrate\n",
      "10/19 election-2-rp and hbe -> %connections target_env_migrate\n",
      "11/19 funding -> %connections target_env_migrate\n",
      "12/19 people.address -> %connections target_env_migrate\n",
      "13/19 people.company_admin -> %connections target_env_migrate\n",
      "14/19 people.employment -> %connections target_env_migrate\n",
      "15/19 people.person -> %connections target_env_migrate\n",
      "16/19 ledger.recurring_premiums -> %connections target_env_migrate\n",
      "17/19 ledger.ledger -> %connections target_env_migrate\n",
      "18/19 ledger.account -> %connections target_env_migrate\n",
      "19/19 ledger.journal_entry - accrue allowance -> %connections target_env_migrate\n",
      "Success!!✅\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create results folder if it does not exist\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "success=True\n",
    "# Iterate over all files in the source folder\n",
    "# for filename in os.listdir(source_folder):\n",
    "\n",
    "for i,filename in enumerate(step_etls):\n",
    "    file_path =  f'{source_folder}//{filename}.ipynb'\n",
    "    \n",
    "    # Check if it is a file (not a directory)\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            notebook_content = f.read()\n",
    "        \n",
    "        # remove all the commented lines \n",
    "        nc=re.sub(r'#.*?\\\\n','',notebook_content) # uncommented notebook_contents\n",
    "        # above line might cause an issue if there are markdown cell before the frist code cell\n",
    "        \n",
    "        # Find connections line\n",
    "        connection_lines = re.findall(r'%connections.*?\\\\n', nc)\n",
    "        \n",
    "        if len(connection_lines) == 1:\n",
    "            # there is a %connections line\n",
    "            b_query = re.findall('bigquery', connection_lines[0])\n",
    "            if len(b_query) > 0:\n",
    "                # bigquery exists\n",
    "                print(f'{i+1}/{total} {filename} -> %connections {target_env}, bigquery')\n",
    "                result = re.sub(r'%connections.*?\\\\n', rf'%connections {target_env}, bigquery\\\\n', notebook_content)\n",
    "                # print(filename)\n",
    "            else:\n",
    "                # no bigquery, only target_envs\n",
    "                print(f'{i+1}/{total} {filename} -> %connections {target_env}')\n",
    "                # print(filename)\n",
    "                result = re.sub(r'%connections.*?\\\\n', rf'%connections {target_env}\\\\n', notebook_content)\n",
    "        elif len(connection_lines) >1:\n",
    "            print(rf'more than 1 %connections line found in {filename}')\n",
    "            success=False\n",
    "            break\n",
    "        else:\n",
    "            print(rf'no %connections line found in {filename}')\n",
    "            result = notebook_content  # No changes made\n",
    "            success=False\n",
    "            break\n",
    "\n",
    "        # Save the modified content to the results folder\n",
    "        result_path = f'{results_folder}//{filename}.ipynb'\n",
    "        with open(result_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(result)\n",
    "    else:\n",
    "        print(f'!!!!!!!!!!!!!!!!!!!! {file_path} does not exist!')\n",
    "        success=False\n",
    "        break\n",
    "if success :\n",
    "    print('Success!!✅')\n",
    "else: \n",
    "    print('FAILED!!!❌')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Upload Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/19 Uploading 1_results\\benefits.company.ipynb to s3://s3_bucket/notebooks/benefits.company.ipynb...\n",
      "2/19 Uploading 1_results\\benefits.company_address.ipynb to s3://s3_bucket/notebooks/benefits.company_address.ipynb...\n",
      "3/19 Uploading 1_results\\benefits.company_onboarding_status.ipynb to s3://s3_bucket/notebooks/benefits.company_onboarding_status.ipynb...\n",
      "4/19 Uploading 1_results\\benefits.hra_program_class.ipynb to s3://s3_bucket/notebooks/benefits.hra_program_class.ipynb...\n",
      "5/19 Uploading 1_results\\benefits.reimbursement_rate.ipynb to s3://s3_bucket/notebooks/benefits.reimbursement_rate.ipynb...\n",
      "6/19 Uploading 1_results\\benefits.rmb_class_zip_county.ipynb to s3://s3_bucket/notebooks/benefits.rmb_class_zip_county.ipynb...\n",
      "7/19 Uploading 1_results\\billing.company.ipynb to s3://s3_bucket/notebooks/billing.company.ipynb...\n",
      "8/19 Uploading 1_results\\election-1-etp.ipynb to s3://s3_bucket/notebooks/election-1-etp.ipynb...\n",
      "9/19 Uploading 1_results\\election-2-rp and hbe.ipynb to s3://s3_bucket/notebooks/election-2-rp and hbe.ipynb...\n",
      "10/19 Uploading 1_results\\election-2-ss and hbe.ipynb to s3://s3_bucket/notebooks/election-2-ss and hbe.ipynb...\n",
      "11/19 Uploading 1_results\\funding.ipynb to s3://s3_bucket/notebooks/funding.ipynb...\n",
      "12/19 Uploading 1_results\\ledger.account.ipynb to s3://s3_bucket/notebooks/ledger.account.ipynb...\n",
      "13/19 Uploading 1_results\\ledger.journal_entry - accrue allowance.ipynb to s3://s3_bucket/notebooks/ledger.journal_entry - accrue allowance.ipynb...\n",
      "14/19 Uploading 1_results\\ledger.ledger.ipynb to s3://s3_bucket/notebooks/ledger.ledger.ipynb...\n",
      "15/19 Uploading 1_results\\ledger.recurring_premiums.ipynb to s3://s3_bucket/notebooks/ledger.recurring_premiums.ipynb...\n",
      "16/19 Uploading 1_results\\people.address.ipynb to s3://s3_bucket/notebooks/people.address.ipynb...\n",
      "17/19 Uploading 1_results\\people.company_admin.ipynb to s3://s3_bucket/notebooks/people.company_admin.ipynb...\n",
      "18/19 Uploading 1_results\\people.employment.ipynb to s3://s3_bucket/notebooks/people.employment.ipynb...\n",
      "19/19 Uploading 1_results\\people.person.ipynb to s3://s3_bucket/notebooks/people.person.ipynb...\n",
      "Upload complete!\n"
     ]
    }
   ],
   "source": [
    "# Define the local directory containing the files to upload\n",
    "local_dir = results_folder  # Change 'source' to your local folder name\n",
    "if success:\n",
    "    # Iterate through the files in the local directory\n",
    "    for root, dirs, files in os.walk(local_dir):\n",
    "        for i,file in enumerate(files):\n",
    "            local_file_path = os.path.join(root, file)\n",
    "            s3_key = prefix + file  # Define the S3 key (path in the bucket)\n",
    "            \n",
    "            # Upload the file\n",
    "            print(f'{i+1}/{len(files)} Uploading {local_file_path} to s3://{bucket_name}/{s3_key}...')\n",
    "            s3.upload_file(local_file_path, bucket_name, s3_key)\n",
    "\n",
    "    print(\"Upload complete!\")\n",
    "else: \n",
    "    print('CHANGE FAILED check above cell!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
