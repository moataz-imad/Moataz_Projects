{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sql_search\"></a>\n",
    "### SQL Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search across SQL files** for keywords, conditions, and patterns. Designed to assist with auditing, debugging, or investigating SQL logic across large codebases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "# from sql_metadata import Parser\n",
    "\n",
    "pd.set_option('display.max_colwidth', 120)  # Show full column content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_search(word_1, word_2, method='both',approximate=False,path=\"queries/*/*.sql\", with_comments=False):\n",
    "    # Validate method\n",
    "    valid_methods = {'both', 'any', 'word_1', 'word_2','word_1_only'}\n",
    "    if method not in valid_methods:\n",
    "        raise ValueError(f\"Invalid method. Choose from {valid_methods}.\")\n",
    "\n",
    "    # Find all .sql files in the queries/*/ directory\n",
    "    sql_files = glob.glob(path,recursive=True) # '../../../**/*.sql' for all the source control\n",
    "    print(f'searching {len(sql_files)} files')\n",
    "    matching_files = []\n",
    "\n",
    "    for sql_file in sql_files:\n",
    "        with open(sql_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            lines = [f'File Name: {sql_file}'] + lines\n",
    "        matches_infile = []\n",
    "        \n",
    "        word_1_found = False\n",
    "        word_2_found = False\n",
    "\n",
    "        for line_number, line in enumerate(lines, start=1):\n",
    "            normalized_line = line.strip().lower()\n",
    "            \n",
    "            cleaned_line = re.sub('--.*','',normalized_line) # with no comments\n",
    "            m={}\n",
    "            \n",
    "            # Check for word_1 using regex\n",
    "            if approximate:\n",
    "                pattern_1=rf'{re.escape(word_1.lower())}'\n",
    "                pattern_2=rf'{re.escape(word_2.lower())}'\n",
    "            else:\n",
    "                pattern_1=rf'\\b{re.escape(word_1.lower())}\\b'\n",
    "                pattern_2=rf'\\b{re.escape(word_2.lower())}\\b'\n",
    "                \n",
    "            if re.search(pattern_1, cleaned_line):\n",
    "                word_1_found = True\n",
    "                # matches.append(f\"Line {line_number}: {line.strip()} (word_1 match)\")\n",
    "                m['file']=sql_file\n",
    "                m['line_number']=line_number\n",
    "                m['line']=line.strip()\n",
    "                m['match']= word_1\n",
    "                matches_infile.append(m)\n",
    "\n",
    "            # Check for word_2 using regex\n",
    "            if re.search(pattern_2, cleaned_line):\n",
    "                word_2_found = True\n",
    "                # matches.append(f\"Line {line_number}: {line.strip()} (word_2 match)\")\n",
    "                m['file']=sql_file\n",
    "                m['line_number']=line_number\n",
    "                m['line']=line.strip()\n",
    "                m['match']= word_2\n",
    "                matches_infile.append(m)\n",
    "\n",
    "        # Determine if the file meets the criteria\n",
    "        if method == 'both' and word_1_found and word_2_found:\n",
    "            matching_files += matches_infile\n",
    "            \n",
    "        elif method == 'any' and (word_1_found or word_2_found):\n",
    "            matching_files += matches_infile\n",
    "        \n",
    "        elif method == 'word_1_only' and (word_1_found and not word_2_found):\n",
    "            matching_files += matches_infile\n",
    "            \n",
    "        elif method == 'word_1' and word_1_found:\n",
    "            matching_files += matches_infile\n",
    "            \n",
    "        elif method == 'word_2' and word_2_found:\n",
    "            matching_files += matches_infile\n",
    "    \n",
    "    results = pd.DataFrame(matching_files, columns=['file','line_number','line','match'])\n",
    "    \n",
    "    if len(matching_files) == 0:\n",
    "        print(f'no match!\\nfor {method}\\n word_1 = {word_1} and word_2 = {word_2}') \n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching 209 files\n",
      "9 matching files\n",
      "queries\\reports\\temp.sql\n",
      "queries\\reports\\v_autopay_profile.sql\n",
      "queries\\reports\\v_autopay_to_reimbursement.sql\n",
      "queries\\reports\\v_booked_deals_platform.sql\n",
      "queries\\reports\\v_company_onboarding.sql\n",
      "queries\\reports\\v_ee_roster.sql\n",
      "queries\\reports\\v_enrollment_app_qa.sql\n",
      "queries\\reports\\v_env_rate_validation.sql\n",
      "queries\\reports\\v_ye_reporting_contacts.sql\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3d97d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3d97d_level0_col0\" class=\"col_heading level0 col0\" >file</th>\n",
       "      <th id=\"T_3d97d_level0_col1\" class=\"col_heading level0 col1\" >line_number</th>\n",
       "      <th id=\"T_3d97d_level0_col2\" class=\"col_heading level0 col2\" >line</th>\n",
       "      <th id=\"T_3d97d_level0_col3\" class=\"col_heading level0 col3\" >match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3d97d_row0_col0\" class=\"data row0 col0\" >queries\\reports\\temp.sql</td>\n",
       "      <td id=\"T_3d97d_row0_col1\" class=\"data row0 col1\" >54</td>\n",
       "      <td id=\"T_3d97d_row0_col2\" class=\"data row0 col2\" >and bcos.status_value not LIKE '%isMigrated%'</td>\n",
       "      <td id=\"T_3d97d_row0_col3\" class=\"data row0 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3d97d_row1_col0\" class=\"data row1 col0\" >queries\\reports\\v_autopay_profile.sql</td>\n",
       "      <td id=\"T_3d97d_row1_col1\" class=\"data row1 col1\" >136</td>\n",
       "      <td id=\"T_3d97d_row1_col2\" class=\"data row1 col2\" >IF(cob.status_value LIKE '%isMigrated%', TRUE, FALSE) is_migrated_client,</td>\n",
       "      <td id=\"T_3d97d_row1_col3\" class=\"data row1 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3d97d_row2_col0\" class=\"data row2 col0\" >queries\\reports\\v_autopay_to_reimbursement.sql</td>\n",
       "      <td id=\"T_3d97d_row2_col1\" class=\"data row2 col1\" >67</td>\n",
       "      <td id=\"T_3d97d_row2_col2\" class=\"data row2 col2\" >IF(cob.status_value LIKE '%isMigrated%', TRUE, FALSE) is_migrated_client,</td>\n",
       "      <td id=\"T_3d97d_row2_col3\" class=\"data row2 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3d97d_row3_col0\" class=\"data row3 col0\" >queries\\reports\\v_booked_deals_platform.sql</td>\n",
       "      <td id=\"T_3d97d_row3_col1\" class=\"data row3 col1\" >22</td>\n",
       "      <td id=\"T_3d97d_row3_col2\" class=\"data row3 col2\" >and cos.status_value not LIKE '%isMigrated%'  -- only net new hra hub companies</td>\n",
       "      <td id=\"T_3d97d_row3_col3\" class=\"data row3 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3d97d_row4_col0\" class=\"data row4 col0\" >queries\\reports\\v_company_onboarding.sql</td>\n",
       "      <td id=\"T_3d97d_row4_col1\" class=\"data row4 col1\" >15</td>\n",
       "      <td id=\"T_3d97d_row4_col2\" class=\"data row4 col2\" >where JSON_EXTRACT_SCALAR(status_value, '$.isMigrated') = 'true')</td>\n",
       "      <td id=\"T_3d97d_row4_col3\" class=\"data row4 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3d97d_row5_col0\" class=\"data row5 col0\" >queries\\reports\\v_ee_roster.sql</td>\n",
       "      <td id=\"T_3d97d_row5_col1\" class=\"data row5 col1\" >80</td>\n",
       "      <td id=\"T_3d97d_row5_col2\" class=\"data row5 col2\" >IF(cob.status_value LIKE '%isMigrated%', true, false) is_migrated_client,</td>\n",
       "      <td id=\"T_3d97d_row5_col3\" class=\"data row5 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3d97d_row6_col0\" class=\"data row6 col0\" >queries\\reports\\v_enrollment_app_qa.sql</td>\n",
       "      <td id=\"T_3d97d_row6_col1\" class=\"data row6 col1\" >138</td>\n",
       "      <td id=\"T_3d97d_row6_col2\" class=\"data row6 col2\" >IF(cob.status_value LIKE '%isMigrated%', TRUE, FALSE) is_migrated_client,</td>\n",
       "      <td id=\"T_3d97d_row6_col3\" class=\"data row6 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3d97d_row7_col0\" class=\"data row7 col0\" >queries\\reports\\v_env_rate_validation.sql</td>\n",
       "      <td id=\"T_3d97d_row7_col1\" class=\"data row7 col1\" >25</td>\n",
       "      <td id=\"T_3d97d_row7_col2\" class=\"data row7 col2\" >and cos2.status_value LIKE '%isMigrated%' and ac.`__hevo__marked_deleted` is not true)</td>\n",
       "      <td id=\"T_3d97d_row7_col3\" class=\"data row7 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3d97d_row8_col0\" class=\"data row8 col0\" >queries\\reports\\v_ye_reporting_contacts.sql</td>\n",
       "      <td id=\"T_3d97d_row8_col1\" class=\"data row8 col1\" >4</td>\n",
       "      <td id=\"T_3d97d_row8_col2\" class=\"data row8 col2\" >join env_prod.benefits_company_onboarding_status bcos on bcos.company_id = bc.id AND bcos.step = 'ACCOUNT' and bcos.`__hevo__marked_deleted` is not TRUE and bcos.status_value LIKE '%isMigrated%'</td>\n",
       "      <td id=\"T_3d97d_row8_col3\" class=\"data row8 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3d97d_row9_col0\" class=\"data row9 col0\" >queries\\reports\\v_ye_reporting_contacts.sql</td>\n",
       "      <td id=\"T_3d97d_row9_col1\" class=\"data row9 col1\" >96</td>\n",
       "      <td id=\"T_3d97d_row9_col2\" class=\"data row9 col2\" >bcos.status_value LIKE '%isMigrated%' migrated_to_hra_hub  -- by default it is false</td>\n",
       "      <td id=\"T_3d97d_row9_col3\" class=\"data row9 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d97d_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3d97d_row10_col0\" class=\"data row10 col0\" >queries\\reports\\v_ye_reporting_contacts.sql</td>\n",
       "      <td id=\"T_3d97d_row10_col1\" class=\"data row10 col1\" >101</td>\n",
       "      <td id=\"T_3d97d_row10_col2\" class=\"data row10 col2\" >join env_prod.benefits_company_onboarding_status bcos on bcos.company_id = bc.id AND bcos.step = 'ACCOUNT' and bcos.`__hevo__marked_deleted` is not TRUE and bcos.status_value not LIKE '%isMigrated%'</td>\n",
       "      <td id=\"T_3d97d_row10_col3\" class=\"data row10 col3\" >isMigrated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22afff0fc70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# Search Configuration\n",
    "# ----------------------------------\n",
    "\n",
    "word_1 = \"isMigrated\"\n",
    "word_2 = \"20245\"\n",
    "method = \"any\"            # Options: 'both', 'any', 'word_1', 'word_2', 'word_1_only'\n",
    "path = 'queries/**/*.sql' # Use glob patterns to control search scope\n",
    "appx = True               # Set to False for strict word-boundary matches\n",
    "\n",
    "# Run search\n",
    "results = sql_search(word_1, word_2, method, appx, path)\n",
    "\n",
    "# ----------------------------------\n",
    "# Ignore List (optional filtering)\n",
    "# ----------------------------------\n",
    "\n",
    "ignorelist = [\n",
    "    r'queries\\manual\\v_report1.sql',\n",
    "    r'queries\\manual\\v_report2.sql',\n",
    "    r'queries\\manual\\v_report3.sql',\n",
    "]\n",
    "\n",
    "# Example: apply filters to refine search results\n",
    "# results = results.query('file in @ignorelist')                         # Include only ignored files\n",
    "# results = results[results.line.str.contains('\\(')]                     # Lines containing parentheses\n",
    "# results = results[~results.line.str.contains('SUBMITTED_TO_CARRIER')]  # Exclude lines with specific text\n",
    "\n",
    "# ----------------------------------\n",
    "# Output & Display\n",
    "# ----------------------------------\n",
    "\n",
    "matching_files = results['file'].unique()\n",
    "print(len(matching_files), 'matching files')\n",
    "for i in matching_files:\n",
    "    print(i)\n",
    "\n",
    "# Export results\n",
    "results.to_csv('matches.csv', index=False)\n",
    "\n",
    "# Optional: Highlight \"File Name\" headers in styled DataFrame\n",
    "def highlight_filename(s):\n",
    "    return ['color:#aaaa00;font-weight:bold' if 'File Name' in str(v) else '' for v in s]\n",
    "\n",
    "# Apply styling in notebook (if needed)\n",
    "# styled_df = results.style.apply(highlight_filename, subset=['line'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Installing collected packages: MarkupSafe, jinja2\n",
      "Successfully installed MarkupSafe-3.0.2 jinja2-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install jinja2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address_id',\n",
       " 'created_at',\n",
       " 'created_by',\n",
       " 'current_workflow_step_id',\n",
       " 'employment_id',\n",
       " 'enrollment_type',\n",
       " 'health_plan_id',\n",
       " 'health_plan_name',\n",
       " 'health_plan_type',\n",
       " 'id',\n",
       " 'is_hsa_qualified',\n",
       " 'is_renewal',\n",
       " 'payment_details_id',\n",
       " 'poc_document_id',\n",
       " 'renewal_health_plan_id',\n",
       " 'shopping_session_id',\n",
       " 'source_health_benefit_election_id',\n",
       " 'source_health_plan_id',\n",
       " 'state',\n",
       " 'updated_at',\n",
       " 'updated_by'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x ={'premium_amount_cents', 'enrollment_status', ' enrollment_type', 'is_primary', 'plan_effective_date', 'plan_end_date',\n",
    "    'carrier_id', 'carrier_name', 'insurance_type', 'plan_market'}\n",
    "y = {'id', 'created_at', 'created_by', 'updated_at', 'updated_by', 'carrier_id', 'carrier_name',\n",
    "    'current_workflow_step_id', 'employment_id', 'enrollment_status', 'enrollment_type', 'health_plan_id', \n",
    "    'health_plan_name', 'health_plan_type', 'is_renewal', 'plan_effective_date', 'poc_document_id', 'premium_amount_cents', \n",
    "    'state', 'address_id', 'shopping_session_id', 'insurance_type', 'is_hsa_qualified', 'is_primary', 'plan_end_date', 'plan_market',\n",
    "    'payment_details_id', 'source_health_benefit_election_id', 'renewal_health_plan_id', 'source_health_plan_id'}\n",
    "y - x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
